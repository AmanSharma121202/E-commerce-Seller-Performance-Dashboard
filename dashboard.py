import streamlit as st
import pandas as pd
import plotly.express as px
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import numpy as np

# --- Page Configuration ---
st.set_page_config(
    page_title="E-commerce Seller Performance Dashboard",
    page_icon="üìä",
    layout="wide"
)

# --- Caching Function for Data Loading ---
@st.cache_data
def load_data():
    """Loads sellers and orders data from CSV files and merges them."""
    try:
        sellers_df = pd.read_csv('sellers.csv')
        orders_df = pd.read_csv('orders.csv')
        sellers_df['seller_join_date'] = pd.to_datetime(sellers_df['seller_join_date'])
        orders_df['order_date'] = pd.to_datetime(orders_df['order_date'])
        df = pd.merge(orders_df, sellers_df, on='seller_id')
        return df
    except FileNotFoundError:
        st.error("Error: 'sellers.csv' or 'orders.csv' not found. Please run the `generate_data.py` script first.")
        return None

# --- Load Data ---
df = load_data()

# --- Main Dashboard ---
st.title("üìä E-commerce Seller Performance Dashboard")

# Stop execution if data loading failed
if df is None:
    st.stop()

# --- KPI Calculations & Display ---
st.header("Overall Performance KPIs")
total_revenue = df[df['is_returned'] == 0]['order_value'].sum()
total_profit = df['profit'].sum()
total_sellers = df['seller_id'].nunique()
total_orders = df['order_id'].nunique()
returned_orders = df['is_returned'].sum()
return_rate = (returned_orders / total_orders) * 100 if total_orders > 0 else 0

col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric(label="Total Revenue", value=f"${total_revenue:,.2f}")
with col2:
    st.metric(label="Total Profit", value=f"${total_profit:,.2f}")
with col3:
    st.metric(label="Total Sellers", value=f"{total_sellers:,}")
with col4:
    st.metric(label="Overall Return Rate", value=f"{return_rate:.2f}%")

st.markdown("---")

# --- Time Series Analysis ---
st.header("Monthly Performance Trends")
df['order_month'] = df['order_date'].dt.to_period('M').astype(str)
monthly_performance = df.groupby('order_month').agg(
    Monthly_Revenue=('order_value', lambda x: x[df.loc[x.index, 'is_returned'] == 0].sum()),
    Monthly_Profit=('profit', 'sum')
).reset_index()

fig_monthly = px.line(
    monthly_performance, x='order_month', y=['Monthly_Revenue', 'Monthly_Profit'],
    title='Monthly Revenue vs. Profit', labels={'order_month': 'Month', 'value': 'Amount (USD)'}, markers=True
)
fig_monthly.update_layout(legend_title_text='Metric', yaxis_title='Amount (USD)', xaxis_title='Month')
st.plotly_chart(fig_monthly, use_container_width=True)

st.markdown("---")

# --- Cohort Analysis ---
st.header("Seller Cohort Analysis: Average Monthly Profit")
st.write("This chart shows the average profit generated by sellers, grouped by the month they joined.")
df['seller_cohort'] = df['seller_join_date'].dt.to_period('M').astype(str)
df['order_period'] = df['order_date'].dt.to_period('M')
df['cohort_index'] = (df['order_period'].dt.year - df['seller_join_date'].dt.year) * 12 + \
                    (df['order_period'].dt.month - df['seller_join_date'].dt.month)
cohort_data = df.groupby(['seller_cohort', 'cohort_index'])['profit'].sum().reset_index()
cohort_sellers = df.groupby(['seller_cohort'])['seller_id'].nunique().reset_index().rename(columns={'seller_id': 'num_sellers'})
cohort_data = pd.merge(cohort_data, cohort_sellers, on='seller_cohort')
cohort_data['avg_profit_per_seller'] = cohort_data['profit'] / cohort_data['num_sellers']
cohort_pivot = cohort_data.pivot_table(index='seller_cohort', columns='cohort_index', values='avg_profit_per_seller')

fig_cohort = px.imshow(
    cohort_pivot, labels=dict(x="Months Since Joining", y="Seller Join Month", color="Avg Profit"),
    title="Average Seller Profit by Cohort", color_continuous_scale=px.colors.sequential.Viridis
)
st.plotly_chart(fig_cohort, use_container_width=True)

st.markdown("---")

# --- Seller Segmentation (K-Means Clustering) ---
st.header("Seller Segmentation")
st.write("Sellers are segmented into clusters based on their performance metrics.")

# 1. Aggregate data at the seller level
seller_metrics = df.groupby('seller_id').agg(
    total_profit=('profit', 'sum'),
    total_orders=('order_id', 'nunique'),
    total_returns=('is_returned', 'sum'),
    avg_order_value=('order_value', 'mean')
).reset_index()
seller_metrics['return_rate'] = (seller_metrics['total_returns'] / seller_metrics['total_orders']) * 100

# 2. Select features and scale them
features = seller_metrics[['total_profit', 'return_rate', 'avg_order_value']]
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

# 3. Perform K-Means Clustering
kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42, n_init=10)
seller_metrics['cluster'] = kmeans.fit_predict(scaled_features)
seller_metrics['cluster'] = seller_metrics['cluster'].astype('category')

# 4. Interpret and name the clusters
cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)
# Find the cluster with the highest profit to name it 'Top Performers'
top_performer_cluster_id = np.argmax(cluster_centers[:, 0]) # 0 is the index for 'total_profit'

cluster_names = {}
# Simple logic to name clusters based on profit ranking
sorted_profit_clusters = np.argsort(cluster_centers[:, 0])[::-1]
name_map = {0: "üèÜ Top Performers", 1: "üìà Steady Sellers", 2: "‚ö†Ô∏è Needs Attention", 3: "üìâ At-Risk"}
for i, cluster_id in enumerate(sorted_profit_clusters):
    cluster_names[cluster_id] = name_map[i]
    
seller_metrics['cluster_name'] = seller_metrics['cluster'].map(cluster_names)


# 5. Visualize the clusters
fig_segmentation = px.scatter(
    seller_metrics,
    x='avg_order_value',
    y='total_profit',
    color='cluster_name',
    size='total_orders',
    hover_name='seller_id',
    hover_data={'total_orders': True, 'return_rate': ':.2f'},
    title='Seller Segments',
    labels={'avg_order_value': 'Average Order Value ($)', 'total_profit': 'Total Profit ($)', 'cluster_name': 'Segment'},
    color_discrete_map={
        "üèÜ Top Performers": "green",
        "üìà Steady Sellers": "blue",
        "‚ö†Ô∏è Needs Attention": "orange",
        "üìâ At-Risk": "red"
    }
)
st.plotly_chart(fig_segmentation, use_container_width=True)

# 6. Display actionable insights
st.subheader("Actionable Insights per Segment")
for name, group in seller_metrics.groupby('cluster_name'):
    with st.expander(f"**{name}** ({len(group)} sellers)"):
        st.write(group.describe())
        if "Top Performers" in name:
            st.success("Recommendation: Reward these sellers with platform benefits, featured placements, or lower commission rates to retain them.")
        elif "Steady Sellers" in name:
            st.info("Recommendation: Engage these sellers with growth programs and tools to help them increase their average order value or reduce return rates.")
        elif "Needs Attention" in name:
            st.warning("Recommendation: Proactively reach out with educational resources on how to improve profitability and manage returns.")
        elif "At-Risk" in name:
            st.error("Recommendation: Investigate the root cause of low profitability. These sellers may need intensive support or may not be a good fit for the platform.")

st.markdown("---")

# --- Display Raw Data (for verification) ---
st.header("Underlying Data")
with st.expander("Show Raw Data"):
    st.dataframe(df.head(100))
